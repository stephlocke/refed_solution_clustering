---
title: ReFed Solutions - Analysis
author: Steph Locke
date: 2022-05-06
output:
  html_document:
    df_print: paged
---

```{r pkgs, echo=FALSE, message=FALSE}
# install.packages(c("tidyverse","tidymodels", "DataExplorer"))
library(tidyverse)
library(tidymodels)
library(DataExplorer)
options(scipen=999)
```

## Source
ReFed is a US nonprofit working to reduce food waste in the US. They make data available on their [ReFed](https://refed.org/) site.

This analysis will use the food waste reduction solutions dataset to help explore which solutions could be looked at in a group.

**There is no public license for this dataset.** It may have been privately provided so no further use of the data from this repository is allowed.

### Data 

```{r coredata, results='hide', message=FALSE}
sol_detail = read_csv("data/ReFED_US_Food_Waste_Solutions_Detail.csv", skip=3)
sol_finance_stakeholder = read_csv("data/ReFED_US_Food_Waste_Solutions_Financial_Summary_by_Stakeholder.csv", skip=3)
sol_summary = read_csv("data/ReFED_US_Food_Waste_Solutions_Summary.csv", skip=3)
sol_finance_stakeholder_state = read_csv("data/ReFED_US_State_Food_Waste_Solutions_Financial_Summary_by_Stakeholder.csv", skip=3)
sol_summary_state = read_csv("data/ReFED_US_State_Food_Waste_Solutions_Summary.csv", skip=3)
```

The below creates data profiles of all the available data.

```{r profile, results='hide'}
# Configure specific for data profile doc
produce_EDA = function(x) DataExplorer::create_report(
                            get(x), 
                            output_file=paste0(x,".html"), 
                            output_dir="eda",
                            report_title=x,
                            config = configure_report(
                                add_plot_qq=FALSE
                            ),
                            quiet=TRUE
                        )

# Produce a profile of each sol dataset if possible
if (rmarkdown::pandoc_available()){
    lapply(ls(pattern="sol_*"), produce_EDA)
}
```

View the profiles of each data set in the `eda/` directory of the project, or if viewing this as a webpage:

- [sol_detail](sol_detail.html)
- [sol_finance_stakeholder](sol_finance_stakeholder.html)
- [sol_summary](sol_summary.html)
- [sol_finance_stakeholder_state](sol_finance_stakeholder_state.html)
- [sol_summary_state](sol_summary_state.html)

## Building a single dataset
We need to get a single dataset suuitable for k-means clustering. 

### Methodology notes
- Features should be numeric and scaled.
- As this is for explanatory purposes, we will not be creating a validation sample.
- The datasets are at different levels of granularity. We will go to the highest level of granularity for initial developement.

### Standardising granularity
```{r single_level}
sol_summary %>%
    group_by(solution_group,solution_priority_action_area,solution_name) %>%
    summarise_if(is.numeric,sum) %>%
    ungroup() ->
    sol_summary_hl

sol_finance_stakeholder  %>%
    group_by(solution_group,solution_priority_action_area,solution_name) %>%
    summarise_if(is.numeric,sum) %>%
    ungroup()  ->
    sol_finance_hl
```

```{r combine_dataset}
sol_summary_hl %>%
    inner_join(sol_finance_hl, by=c("solution_group","solution_priority_action_area","solution_name")) %>%
    select(-(solution_group:solution_priority_action_area)) %>%
    select(-ends_with(".y")) ->
    sol_hl

sol_hl
```

## Build a model

```{r prepare_data}
recipe(~., data=sol_hl) %>%
  step_normalize(all_numeric_predictors()) %>%
  update_role(solution_name, new_role = "id variable") %>%
  prep() ->
  processor

sol = bake(processor, sol_hl)
summary(sol)
```

The following code aligns to the sample code in [tidymodels](https://www.tidymodels.org/learn/statistics/k-means/). 

It runs many clustering models and extract key results.

```{r kmeans_cluster}
 tibble(k = 1:9) %>%
  mutate(
    kclust = map(k, ~kmeans(sol[,-1], .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, sol)
  ) ->
  cluster_results
```

We can then split out the results into easier to use objects.
```{r split_results}
cluster_results %>%
  unnest(cols = c(tidied)) ->
  clusters

cluster_results %>% 
  unnest(cols = c(augmented)) ->
  assignments

cluster_results %>%
  unnest(cols = c(glanced)) ->
  clusterings
```

## Visualise results
We can look at the results of the clustering models split by key factors, bearing in mind the clustering is based on all numeric variables not just the ones shown.
```{r cluster_groups}
p1 = ggplot(assignments, aes(x = annual_us_dollars_net_financial_benefit.x, y = annual_meal_equivalents_diverted)) +
  geom_point(aes(color = .cluster), alpha = 0.8) + 
  facet_wrap(~ k) +
  geom_point(data = clusters, size = 10, shape = "x")

p1
```

We can then explore the fit of the differing number of clusters to see where we get a diminishing returns.
```{r k_fit}
ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point()
```

## Explore k=5 results
It looks like 4-6 clusters is a good fit so let's look at the the groupings for k=5.

```{r k_5_summary}
assignments %>%
    filter(k==5) %>%
    select(solution_name, .cluster) %>%
    inner_join(sol_hl) %>%
    group_by(.cluster) %>%
    summarise_if(is.numeric,.funs=c("mean","min", "max")) %>%
    pivot_longer(cols=-.cluster) %>%
    pivot_wider(names_from=.cluster)
```

```{r cluster_points}
clusters %>%
    filter(k==5) %>%
    select(-kclust, -glanced, -augmented, -k, -withinss, -size) %>%
    pivot_longer(cols=-cluster) %>%
    ggplot( aes(x=name, y=value, colour=cluster, group=cluster)) +
     geom_line() +
     coord_flip() 
```

```{r k_5_assignments}
assignments %>%
    filter(k==5) %>%
    select(solution_name, .cluster) %>%
    inner_join(sol_hl) %>%
    arrange(.cluster, desc(annual_us_dollars_net_financial_benefit.x))
```

