---
title: ReFed Solutions - Analysis
author: Steph Locke
date: 2022-01-06
output:
  html_document:
    df_print: paged
---

```{r pkgs, echo=FALSE, message=FALSE}
# install.packages(c("tidyverse","tidymodels", "DataExplorer"))
library(tidyverse)
library(tidymodels)
library(DataExplorer)
library(svglite)
options(scipen=999)
```

## Source
ReFed is a US nonprofit working to reduce food waste in the US. They make data available on their [ReFed](https://refed.org/) site.

This analysis will use the food waste reduction solutions dataset to help explore which solutions could be looked at in a group.

**There is no public license for this dataset.** It may have been privately provided so no further use of the data from this repository is allowed.

### Data 

```{r coredata, results='hide', message=FALSE}
sol_detail = read_csv("data/ReFED_US_Food_Waste_Solutions_Detail.csv", skip=3)
sol_finance_stakeholder = read_csv("data/ReFED_US_Food_Waste_Solutions_Financial_Summary_by_Stakeholder.csv", skip=3)
sol_summary = read_csv("data/ReFED_US_Food_Waste_Solutions_Summary.csv", skip=3)
sol_finance_stakeholder_state = read_csv("data/ReFED_US_State_Food_Waste_Solutions_Financial_Summary_by_Stakeholder.csv", skip=3)
sol_summary_state = read_csv("data/ReFED_US_State_Food_Waste_Solutions_Summary.csv", skip=3)
```

The below creates data profiles of all the available data.

```{r profile, results='hide'}
# Configure specific for data profile doc
produce_EDA = function(x) DataExplorer::create_report(
                            get(x), 
                            output_file=paste0(x,".html"), 
                            output_dir="eda",
                            report_title=x,
                            config = configure_report(
                                add_plot_qq=FALSE
                            ),
                            quiet=TRUE
                        )

# Produce a profile of each sol dataset if possible
if (rmarkdown::pandoc_available()){
    lapply(ls(pattern="sol_*"), produce_EDA)
}
```

View the profiles of each data set in the `eda/` directory of the project, or if viewing this as a webpage:

- [sol_detail](sol_detail.html)
- [sol_finance_stakeholder](sol_finance_stakeholder.html)
- [sol_summary](sol_summary.html)
- [sol_finance_stakeholder_state](sol_finance_stakeholder_state.html)
- [sol_summary_state](sol_summary_state.html)

## Building a single dataset
We need to get a single dataset suuitable for k-means clustering. 

### Methodology notes
- Features should be numeric and scaled.
- As this is for explanatory purposes, we will not be creating a validation sample.
- The datasets are at different levels of granularity. We will go to the highest level of granularity for initial developement.

### Standardising granularity
We will remove consumer and government as stakeholders for the scenario we're building.
```{r single_level}
sol_summary %>%
    group_by(solution_group,solution_priority_action_area,solution_name) %>%
    summarise_if(is.numeric,sum) %>%
    ungroup() ->
    sol_summary_hl

sol_finance_stakeholder  %>%
    filter(!stakeholder %in% c("Consumers","Government")) %>%
    group_by(solution_group,solution_priority_action_area,solution_name) %>%
    summarise_if(is.numeric,sum) %>%
    ungroup()  ->
    sol_finance_hl
```

How many viable solutions have been identified as having capturable revenue?
```{r check_row_count}
nrow(sol_finance_hl)
```


Use the stakeholder filtered calcs where column names overlap. Add a profit column based on net financial benefit and the gross financial benefit. Then select only metrics that matter to scenario.
```{r combine_dataset}
sol_summary_hl %>%
    inner_join(sol_finance_hl, by=c("solution_group","solution_priority_action_area","solution_name"),
    suffix=c(".x","")) %>%
    select(-(solution_group:solution_priority_action_area)) %>%
    select(-ends_with(".x")) %>% 
    mutate(profit_margin = annual_us_dollars_net_financial_benefit / max(annual_us_dollars_gross_financial_benefit,1)) %>%
    select(solution_name, annual_meal_equivalents_diverted,
            profit_margin, annual_gallons_water_savings_potential,
            jobs_created, annual_mtco2e_reduction_potential,
            annual_us_dollars_gross_financial_benefit) ->
    sol_hl

sol_hl
```

## Build a model

```{r prepare_data}
recipe(~., data=sol_hl) %>%
  step_normalize(all_numeric_predictors()) %>%
  update_role(solution_name, new_role = "id variable") %>%
  prep() ->
  processor

sol = bake(processor, sol_hl)

sol
```

The following code aligns to the sample code in [tidymodels](https://www.tidymodels.org/learn/statistics/k-means/). 

It runs many clustering models and extract key results.

```{r kmeans_cluster}
set.seed(42)
tibble(k = 2:12) %>%
  mutate(
    kclust = map(k, ~kmeans(sol[,-1], .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, sol)
  ) ->
  cluster_results
```

We can then split out the results into easier to use objects.
```{r split_results}
cluster_results %>%
  unnest(cols = c(tidied)) ->
  clusters

cluster_results %>% 
  unnest(cols = c(augmented)) ->
  assignments

cluster_results %>%
  unnest(cols = c(glanced)) ->
  clusterings
```

## Visualise results
We can look at the results of the clustering models split by key factors, bearing in mind the clustering is based on all numeric variables not just the ones shown.
```{r cluster_groups}
p1 = ggplot(assignments, aes(x = profit_margin, y = annual_meal_equivalents_diverted)) +
  geom_point(aes(color = .cluster), alpha = 0.8) + 
  facet_wrap(~ k) +
  geom_point(data = clusters, size = 10, shape = "x")

p1
```

We can then explore the fit of the differing number of clusters to see where we get a diminishing returns.
```{r k_fit}
ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  scale_x_continuous(n.breaks=12) ->
  k_fit

k_fit
```

What value for k should we pick? Let's look at the relative difference in tot.withinss reduction between k values.

```{r totreduction}
improvement_threshold = .9
clusterings %>%
  select(k, tot.withinss) %>%
  mutate(rel_tot_withinss = tot.withinss / lag(tot.withinss)) %>%
  mutate(improvement_change = rel_tot_withinss <improvement_threshold
               & lead(rel_tot_withinss) >improvement_threshold) %>%
  filter(improvement_change) %>%
  filter(k==min(k)) ->
  best_k

best_k
```
## Explore results for best value of k

Here are the average values for all solutions within a given cluster.
```{r k_5_summary}
assignments %>%
    filter(k==6) %>%
    select(solution_name, .cluster) %>%
    inner_join(sol_hl) %>%
    group_by(.cluster) %>%
    summarise_if(is.numeric,mean) %>%
    pivot_longer(cols=-.cluster) %>%
    pivot_wider(names_from=.cluster)
```

What are the centroids according to the model?
The normalized version presents the clusters as distances from the average value for the column.

- -1 is one standard deviation less than the mean
- 0 is the mean
- 1 is one standard deviation more than the mean
```{r cluster_points}
clusters %>%
    filter(k==best_k$k) %>%
    select(-kclust, -glanced, -augmented, -k, -withinss, -size) %>%
    pivot_longer(cols=-cluster) %>%
    ggplot( aes(x=name, y=value, colour=cluster, group=cluster)) +
     geom_line() +
     coord_flip() +
     labs(y="Centroid sd away from mean for col", x="Column") +
     theme_minimal() +
     scale_y_continuous(n.breaks=6) ->
     cluster_centroids

cluster_centroids
```

What clusters are each solution in?
```{r k_5_assignments}
assignments %>%
    filter(k==best_k$k) %>%
    select(solution_name, .cluster) %>%
    inner_join(sol_hl) %>%
    arrange(.cluster, desc(annual_us_dollars_gross_financial_benefit))
```

Which cluster meets our criteria? ie which one(s) have higher than average impact in the three measures
```{r best_cluster}
clusters %>%
    filter(k==best_k$k) %>%
    filter(profit_margin>1,
    annual_us_dollars_gross_financial_benefit>1,
    annual_meal_equivalents_diverted>1) %>%
    select(cluster,annual_meal_equivalents_diverted:annual_us_dollars_gross_financial_benefit) ->
    best_cluster

best_cluster
```

Let's see what's in the best cluster.
```{r cluster_3}
assignments %>%
  filter(k==best_k$k, .cluster %in% best_cluster$cluster) %>%
  select(solution_name, .cluster) %>%
  inner_join(sol_hl) %>%
  arrange(desc(annual_meal_equivalents_diverted), desc(profit_margin),
    desc(annual_us_dollars_gross_financial_benefit), desc(jobs_created),
    desc(annual_mtco2e_reduction_potential), desc( annual_gallons_water_savings_potential)) 
```

## Make outputs
Create CSVs for prettification in Power BI!

### Cluster centroids
These are the centers of clusters to help understand the different groups.

The normalized version presents the clusters as distances from the average value for the column.

- -1 is one standard deviation less than the mean
- 0 is the mean
- 1 is one standard deviation more than the mean
```{r make_centroid_outputs}
clusters %>%
    filter(k==best_k$k) %>%
    select(-kclust, -glanced, -augmented, -k, -withinss, -size) %>%
    pivot_longer(cols=-cluster) %>% 
    write_csv(file = "outputs/clusters_normalized.csv")
```

- [clusters_normalized.csv](outputs/clusters_normalized.csv)

### Cluster assignments
A simple CSV with the solution name and the cluster it belongs to

```{r make_cluster_assignments_outputs}
assignments %>%
    filter(k==best_k$k) %>%
    select(solution_name, .cluster) %>%
    write_csv(file = "outputs/cluster_assignments.csv")
```

- [cluster_assignments.csv](outputs/cluster_assignments.csv)

### Charts
Save the chart showing the measure of fit for cluster models (as this show's 2-9 and 9-12 it can be reused)
```{r k212_eval}
ggsave("outputs/k212_evaluation.svg", k_fit)
```

- [k212_evaluation.svg](outputs/k212_evaluation.svg)

Save the chart showing the cluster centers for features for k=5
```{r k5_centroids}
ggsave("outputs/cluster_centroids.svg", cluster_centroids)
```

- [cluster_centroids.svg](outputs/cluster_centroids.svg)